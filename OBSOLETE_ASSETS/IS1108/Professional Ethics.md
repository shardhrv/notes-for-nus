[[IS1108 Home Page]] 

Computing professionals have an ethical responsibility towards different stakeholders - each coming with their own ethical concerns. 

| **Stakeholder**     | **Ethical concern**                                        |
| ------------------- | ---------------------------------------------------------- |
| Customer and users  | Social impact, Quality & Risks, Data Privacy               |
| Employers           | Intellectual Property, Conflict of interest                |
| Other Professionals | Plagiarism, Professional Standards and Conduct, Mentorship |
| Public              | Safety, Whistleblowing                                     |

The question is how do we go about to weigh each of these ethical considerations against one another? 

### Ethical Frameworks

- [[Consequentialist]]
- [[Duty]] 
- [[Virtue]]

### Application for Computing Professionals

![[IS1108 - Table 1.png]]



## Professional Ethics
- Honesty 
- Trustworthiness  
- Loyalty  
- Respect for others  
- Adherence to the law  
- Doing good and avoiding harm to others  
- Accountability

## Using the Ethical Frameworks

**Scenario:** You are a software engineer working for a company that develops  
autonomous driving software. You're currently working on an update to the  
decision-making algorithms for emergency scenarios. A recently surfaced issue is the "trolley problem," a hypothetical situation where the autonomous vehicle must choose between two harmful outcomes:  
- The car, to avoid a group of five pedestrians who suddenly appear in its path, could swerve into a wall, likely seriously injuring the single passenger inside.
- The car could continue on its path, likely injuring or even killing the five pedestrians.  

Should you modify the algorithm to always prioritize the lives of multiple people over one, even if that one is the passenger?

### Possible Solutions

##### Option A
Implement the change, as protecting multiple lives over one is ethically permissible, even if it harms the passenger.
##### Option B
Reject the change, as it's not ethically permissible to directly harm the passenger, regardless of the potential benefits.
##### Option C
Implement the change, but also inform all potential customers about this feature, allowing them to make an informed decision.
##### Option D
Reject the change and seek a third solution that doesn't risk harming either the passenger or pedestrians.

##### Consequentialist:
This theory would likely favor Option A, as it prioritizes the greatest good for the greatest number (i.e., saving multiple pedestrians over one passenger).

##### Duty:
This theory focuses on duties and rules. It might lean towards Option B because it emphasizes the autonomous vehicle's duty not to harm its passenger. However, a deontologist could also argue for Option D, seeking a solution that fulfills the duty not to harm anyone if possible

##### Virtue:
This perspective focuses on character and the kinds of virtues (or moral character traits) one should cultivate. A virtue ethicist might argue for Option C or Option D, as these options show a concern for transparency, respect for all parties involved, and a willingness to seek better solutions.

## Principle of Double Effects (PDE)

**Definition:** if an action has two possible outcomes - one good and one bad - then it is still permissible to perform if the actor intends only for the good outcome and takes reasonable steps to prevent or minimise the bad outcome. 

